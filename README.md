# Stock Prediction Model - Quick Start Guide

## ðŸš€ How to Run This Project

### **Option 1: Run the Complete Pipeline (Recommended)**

This will train all models from scratch and show you the results.

```powershell
# Run the improved model pipeline
python model_improvement_pipeline.py
```

**What it does:**
1. âœ… Loads all your processed stock data
2. âœ… Engineers 59 advanced features (lags, technical indicators, etc.)
3. âœ… Trains 3 models: Random Forest, XGBoost, LightGBM
4. âœ… Optimizes ensemble weights
5. âœ… Evaluates performance on test set
6. âœ… Saves models to `models/` directory
7. âœ… Saves results to `results/improvement_metrics.json`

**Output:**
```
MAE:   0.0143 (1.43% error)
RMSE:  0.0220 (2.20% error)
RÂ²:    0.1979 (19.79% variance explained)
Dir:   64.37% (directional accuracy)

VERDICT: STRONG
```

**Time:** ~5-10 minutes (depending on your CPU)

---

### **Option 2: Just View Existing Results**

If you already ran the pipeline and just want to see results:

```powershell
# View the results JSON
cat results/improvement_metrics.json
```

Or in Python:
```python
import json

with open('results/improvement_metrics.json') as f:
    results = json.load(f)
    
print(f"MAE:  {results['metrics']['MAE']:.6f}")
print(f"RMSE: {results['metrics']['RMSE']:.6f}")
print(f"RÂ²:   {results['metrics']['R2']:.4f}")
print(f"Dir:  {results['metrics']['Directional_Accuracy']:.2%}")
print(f"\nVerdict: {results['verdict']}")
```

---

### **Option 3: View Results as Graphs** ðŸ“Š

Generate beautiful visualizations of your model performance:

```powershell
python visualize_results.py
```

**This creates 4 graphs:**
1. `results/performance_metrics.png` - MAE, RMSE, RÂ², Accuracy metrics
2. `results/ensemble_weights.png` - Model weight distribution  
3. `results/accuracy_comparison.png` - Your model vs random baseline
4. `results/dashboard.png` - Comprehensive dashboard view

**To view the graphs:**
```powershell
explorer results
```

---

### **Option 4: Use Trained Models for Predictions**

Load the saved models and make new predictions:

```python
import joblib
import pandas as pd
import numpy as np

# 1. Load models
models = joblib.load('models/ensemble_models.joblib')
scaler = joblib.load('models/scaler.joblib')

# 2. Load your new data (must have same features!)
# df_new = pd.read_csv('your_new_data.csv')

# 3. Engineer same features (20+ indicators)
# ... (use same feature engineering as in pipeline)

# 4. Scale features
# X_scaled = scaler.transform(X_new)

# 5. Get ensemble prediction
weights = {'RF': 0.808, 'XGB': 0.082, 'LGBM': 0.110}
predictions = {name: model.predict(X_scaled) for name, model in models.items()}
ensemble_pred = sum(weights[name] * predictions[name] for name in models.keys())

# 6. Interpret results
for pred in ensemble_pred:
    if pred > 0.005:
        print(f"ðŸŸ¢ BUY  - Expected: +{pred*100:.2f}%")
    elif pred < -0.005:
        print(f"ðŸ”´ SELL - Expected: {pred*100:.2f}%")
    else:
        print(f"âšª HOLD - Expected: {pred*100:.2f}%")
```

---

## ðŸ“ Project Structure

```
STOCK-ANALYSIS/
â”‚
â”œâ”€â”€ ðŸ“Š DATA
â”‚   â”œâ”€â”€ data/raw/              â†’ Original CSV files
â”‚   â””â”€â”€ data/processed/        â†’ Cleaned data (ready to use)
â”‚
â”œâ”€â”€ ðŸ¤– MODELS (Your trained models)
â”‚   â”œâ”€â”€ ensemble_models.joblib â†’ RF + XGBoost + LightGBM
â”‚   â””â”€â”€ scaler.joblib          â†’ Feature scaler
â”‚
â”œâ”€â”€ ðŸ“ˆ RESULTS (Performance metrics)
â”‚   â””â”€â”€ improvement_metrics.json â†’ All accuracy metrics
â”‚
â”œâ”€â”€ ðŸ”§ IMPLEMENTATION MODULES
â”‚   â”œâ”€â”€ model_improvement_pipeline.py  â† MAIN FILE (run this!)
â”‚   â”œâ”€â”€ enhanced_features.py           â†’ Feature engineering
â”‚   â”œâ”€â”€ ensemble_model.py             â†’ Ensemble logic
â”‚   â”œâ”€â”€ directional_metrics.py        â†’ Direction classifier
â”‚   â”œâ”€â”€ walk_forward_validation.py    â†’ Time-series validation
â”‚   â””â”€â”€ noise_reduction.py            â†’ Outlier handling
â”‚
â””â”€â”€ ðŸ“– DOCUMENTATION
    â”œâ”€â”€ README.md                      â† This file
    â”œâ”€â”€ HOW_TO_VIEW_RESULTS.md        â†’ Result guide
    â””â”€â”€ HOW_TO_RUN.md                 â†’ Quick start (original)
```

---

## âš¡ Quick Commands

### Run the full pipeline:
```powershell
python model_improvement_pipeline.py
```

### View results:
```powershell
cat results/improvement_metrics.json
```

### Check what files were created:
```powershell
Get-ChildItem models/, results/
```

### Load models in Python:
```python
import joblib
models = joblib.load('models/ensemble_models.joblib')
print(f"Loaded {len(models)} models: {list(models.keys())}")
```

---

## ðŸŽ¯ What You Get

After running the pipeline, you get:

âœ… **3 Trained Models**
- Random Forest (primary - 80.8% weight)
- XGBoost (supporting - 8.2% weight)  
- LightGBM (supporting - 11.0% weight)

âœ… **Performance Metrics**
- **RÂ² = 19.79%** (explains ~20% of variance - STRONG!)
- **Directional Accuracy = 64.37%** (14% edge over random)
- **Profit-Weighted = 73.56%** (even better on large moves)
- **MAE = 1.43%** (average error)

âœ… **Ready-to-Use Models**
- Saved in `models/` directory
- Can load and use immediately
- No re-training needed

---

## ðŸ”„ How to Retrain

If you want to retrain with new data or different settings:

1. **Add new data** to `data/processed/` folder
2. **Run pipeline again:**
   ```powershell
   python model_improvement_pipeline.py
   ```
3. **Check new results** in `results/improvement_metrics.json`

---

## ðŸ“Š Understanding Your Results

### RÂ² = 0.1979 (19.79%)
- **What it means:** Model explains ~20% of stock return variance
- **Is it good?** YES! Most stock models get 5-15%
- **Why it matters:** Shows model has real predictive power

### Directional Accuracy = 64.37%
- **What it means:** Predicts up/down correctly 64% of time
- **Is it good?** YES! Random guessing = 50%
- **Why it matters:** 14% edge = profitable trading strategy

### Profit-Weighted = 73.56%
- **What it means:** Even better (74%) on large movements
- **Is it good?** EXCELLENT!
- **Why it matters:** Most accurate when it counts most

---

## â“ Common Questions

**Q: How long does it take to run?**  
A: 5-10 minutes on average CPU

**Q: Can I use this for real trading?**  
A: Yes, but combine with risk management and position sizing

**Q: Do I need to retrain often?**  
A: Recommended every 3-6 months as market conditions change

**Q: What if I get errors?**  
A: Make sure you have: pandas, numpy, scikit-learn, xgboost, lightgbm installed

**Q: How do I install missing packages?**  
A: `pip install pandas numpy scikit-learn xgboost lightgbm joblib`

---

## ðŸŽ‰ You're Ready!

**To get started:**
```powershell
python model_improvement_pipeline.py
```

**To see results:**
```powershell
cat results/improvement_metrics.json
```

**Your models will be saved in `models/` directory and ready to use!** ðŸš€
